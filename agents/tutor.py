from __future__ import annotations
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from rag.retriever import get_retriever


SYSTEM = """ë„ˆëŠ” ì£¼ì‹/ETF ì™•ì´ˆë³´(ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ì¤€)ë¥¼ ê°€ë¥´ì¹˜ëŠ” íŠœí„°ë‹¤.

ê·œì¹™:
- ì•„ì£¼ ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•œë‹¤.
- í•œ ë¬¸ì¥ì€ ì§§ê²Œ ì“´ë‹¤.
- ë¹„ìœ ë¥¼ ê¼­ ë„£ëŠ”ë‹¤.
- ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ë°”ë¡œ í’€ì´í•œë‹¤.

â­ ì´ëª¨í‹°ì½˜ ê·œì¹™(ë°˜ë“œì‹œ ì§€ì¼œ):
- ê° í•­ëª© ì œëª© ì•ì—ëŠ” ì•„ë˜ ì´ëª¨í‹°ì½˜ì„ ë¶™ì¸ë‹¤.
- ì´ëª¨í‹°ì½˜ì€ í•­ìƒ ê°™ì€ ê²ƒì„ ì“´ë‹¤.

ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì§€ì¼œ):
ğŸ“Œ í•œì¤„ ì •ì˜:
ğŸ§  ì‰¬ìš´ ì˜ˆì‹œ:
â“ ì™œ ì¤‘ìš”í•œê°€:
âš ï¸ ì£¼ì˜í•  ì :
ğŸ“ 3ì¤„ ìš”ì•½:
"""


def answer_term_question(question: str) -> str:
    load_dotenv()
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)

    retriever = get_retriever(k=4)
    docs = retriever.invoke(question)
    context = "\n\n---\n\n".join([f"[source={d.metadata.get('source','')}] {d.page_content}" for d in docs])

    prompt = f"""{SYSTEM}

[ì§ˆë¬¸]
{question}

[RAG ì»¨í…ìŠ¤íŠ¸]
{context}
"""
    resp = llm.invoke(prompt)
    return resp.content
